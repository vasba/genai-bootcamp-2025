version: '3'
services:
  llm:
    image: opea/llm-textgen:latest
    environment:
      - MODEL_ID=${LLM_MODEL_ID:-meta-llama/Llama-2-7b-chat}
      - HUGGINGFACEHUB_API_TOKEN=${HUGGINGFACEHUB_API_TOKEN}
    ports:
      - "8008:80"

  embedding:
    image: opea/embedding:latest
    ports:
      - "8001:80"

  retriever:
    image: opea/retriever:latest
    ports:
      - "7000:7000"
    volumes:
      - ./data:/app/data

  translation:
    image: opea/translation:latest
    ports:
      - "8002:80"
    environment:
      - MODEL_ID=${TRANSLATION_MODEL_ID:-facebook/mbart-large-50-many-to-many-mmt}

  expertqa:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8888:8888"
    environment:
      - EMBEDDING_SERVER_HOST_IP=embedding
      - EMBEDDING_SERVER_PORT=80
      - RETRIEVER_SERVICE_HOST_IP=retriever
      - RETRIEVER_SERVICE_PORT=7000
      - LLM_SERVER_HOST_IP=llm
      - LLM_SERVER_PORT=80
      - TRANSLATION_SERVER_HOST_IP=translation
      - TRANSLATION_SERVER_PORT=80
    depends_on:
      - llm
      - embedding
      - retriever
      - translation

  nginx:
    image: opea/nginx:latest
    ports:
      - "${NGINX_PORT:-80}:80"
    depends_on:
      - expertqa