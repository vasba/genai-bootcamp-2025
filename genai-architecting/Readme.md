## Functional Requirements

The startup wants to use existing infrastructure consisting of a computer with:

- Corsair 32GB (2x16GB) DDR4 3200MHz CL16 Vengean, RAM
- AMD Ryzen 7 5800X3D 3.4 GHz 100MB, CPU
- Gigabyte GeForce RTX 4070 12GB Windforce X2 OC

The reason is to first test the market fit of the app before investing into an AI computer or hosting in a cloud service.
The focus is accuracy over speed.

## Assuptions

We are assuming that the Open source LLM will give acurate responses on the above hardware even if somehow slow measured in outputed tokens per seconds.

## Considerations

We consider using a trully open source model like IBM Granite
